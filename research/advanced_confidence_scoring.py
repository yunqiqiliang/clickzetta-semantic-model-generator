#!/usr/bin/env python3
"""
Advanced Multi-Factor Confidence Scoring Model for Relationship Discovery

This module implements a sophisticated confidence scoring system based on academic research
and best practices for foreign key discovery, integrating multiple evidence sources.
"""

import math
import re
from typing import Dict, List, Tuple, Optional, Set
from dataclasses import dataclass
from enum import Enum


class EvidenceType(Enum):
    """Types of evidence for relationship confidence."""
    NAME_SIMILARITY = "name_similarity"
    TYPE_COMPATIBILITY = "type_compatibility"
    VALUE_CONTAINMENT = "value_containment"
    SCHEMA_PATTERNS = "schema_patterns"
    DOMAIN_KNOWLEDGE = "domain_knowledge"
    STATISTICAL_ANALYSIS = "statistical_analysis"
    CARDINALITY_ANALYSIS = "cardinality_analysis"


@dataclass
class ConfidenceEvidence:
    """Represents a piece of evidence for relationship confidence."""
    evidence_type: EvidenceType
    score: float  # 0.0 to 1.0
    weight: float  # Relative importance
    explanation: str
    confidence_level: str  # "high", "medium", "low"


@dataclass
class RelationshipCandidate:
    """Enhanced relationship candidate with detailed confidence analysis."""
    fk_table: str
    fk_column: str
    pk_table: str
    pk_column: str
    evidence_scores: Dict[EvidenceType, ConfidenceEvidence]
    final_confidence: float
    quality_tier: str  # "excellent", "good", "fair", "poor"
    recommendation: str


class AdvancedConfidenceScorer:
    """
    Advanced confidence scoring system implementing multi-factor analysis
    based on academic research in foreign key discovery.
    """

    def __init__(self):
        # TPC-H specific entity mappings
        self.tpch_entities = {
            "CUSTOMER": ["CUST", "C"],
            "SUPPLIER": ["SUPP", "S"],
            "PART": ["P"],
            "ORDERS": ["ORDER", "O"],
            "LINEITEM": ["LINE", "L"],
            "PARTSUPP": ["PS"],
            "NATION": ["N"],
            "REGION": ["R"]
        }

        # Reverse mapping for quick lookup
        self.entity_abbreviations = {}
        for entity, abbrevs in self.tpch_entities.items():
            for abbrev in abbrevs:
                self.entity_abbreviations[abbrev] = entity

        # Business relationship patterns with confidence weights
        self.business_patterns = {
            ("CUSTOMER", "ORDERS"): {"weight": 0.95, "pattern": "customer-orders"},
            ("ORDERS", "LINEITEM"): {"weight": 0.90, "pattern": "orders-lineitem"},
            ("PART", "LINEITEM"): {"weight": 0.85, "pattern": "part-lineitem"},
            ("SUPPLIER", "LINEITEM"): {"weight": 0.80, "pattern": "supplier-lineitem"},
            ("PART", "PARTSUPP"): {"weight": 0.90, "pattern": "part-partsupp"},
            ("SUPPLIER", "PARTSUPP"): {"weight": 0.90, "pattern": "supplier-partsupp"},
            ("NATION", "CUSTOMER"): {"weight": 0.75, "pattern": "nation-customer"},
            ("NATION", "SUPPLIER"): {"weight": 0.75, "pattern": "nation-supplier"},
            ("REGION", "NATION"): {"weight": 0.85, "pattern": "region-nation"}
        }

        # Data type compatibility matrix
        self.type_compatibility = {
            ("NUMBER", "NUMBER"): 1.0,
            ("INTEGER", "INTEGER"): 1.0,
            ("BIGINT", "BIGINT"): 1.0,
            ("NUMBER", "INTEGER"): 0.9,
            ("INTEGER", "BIGINT"): 0.8,
            ("STRING", "STRING"): 1.0,
            ("VARCHAR", "VARCHAR"): 1.0,
            ("TEXT", "TEXT"): 1.0,
            ("STRING", "VARCHAR"): 0.9,
            ("VARCHAR", "TEXT"): 0.8,
        }

        # Evidence weights (sum to 1.0)
        self.evidence_weights = {
            EvidenceType.NAME_SIMILARITY: 0.25,
            EvidenceType.TYPE_COMPATIBILITY: 0.15,
            EvidenceType.VALUE_CONTAINMENT: 0.20,
            EvidenceType.SCHEMA_PATTERNS: 0.15,
            EvidenceType.DOMAIN_KNOWLEDGE: 0.15,
            EvidenceType.STATISTICAL_ANALYSIS: 0.05,
            EvidenceType.CARDINALITY_ANALYSIS: 0.05
        }

    def calculate_name_similarity_evidence(
        self,
        fk_column: str,
        pk_column: str,
        fk_table: str,
        pk_table: str
    ) -> ConfidenceEvidence:
        """Calculate name similarity evidence with TPC-H awareness."""

        # Extract core entities
        fk_core = self._extract_core_entity(fk_column)
        pk_core = self._extract_core_entity(pk_column)

        # Calculate various similarity metrics
        exact_match = fk_column.upper() == pk_column.upper()
        core_match = fk_core == pk_core if fk_core and pk_core else False
        entity_variant_match = self._are_entity_variants(fk_core, pk_core)
        levenshtein_sim = self._calculate_levenshtein_similarity(fk_column, pk_column)

        # Weighted scoring
        if exact_match:
            score = 1.0
            explanation = f"Exact column name match: {fk_column} = {pk_column}"
            confidence_level = "high"
        elif core_match:
            score = 0.95
            explanation = f"Perfect core entity match: {fk_core} = {pk_core}"
            confidence_level = "high"
        elif entity_variant_match:
            score = 0.90
            explanation = f"Entity variant match: {fk_core} ‚Üî {pk_core}"
            confidence_level = "high"
        elif levenshtein_sim >= 0.8:
            score = 0.70 + (levenshtein_sim - 0.8) * 0.5  # 0.70-0.80
            explanation = f"High string similarity: {levenshtein_sim:.3f}"
            confidence_level = "medium"
        elif levenshtein_sim >= 0.6:
            score = 0.40 + (levenshtein_sim - 0.6) * 1.5  # 0.40-0.70
            explanation = f"Moderate string similarity: {levenshtein_sim:.3f}"
            confidence_level = "medium"
        else:
            score = min(0.40, levenshtein_sim)
            explanation = f"Low string similarity: {levenshtein_sim:.3f}"
            confidence_level = "low"

        return ConfidenceEvidence(
            evidence_type=EvidenceType.NAME_SIMILARITY,
            score=score,
            weight=self.evidence_weights[EvidenceType.NAME_SIMILARITY],
            explanation=explanation,
            confidence_level=confidence_level
        )

    def calculate_type_compatibility_evidence(
        self,
        fk_type: str,
        pk_type: str
    ) -> ConfidenceEvidence:
        """Calculate type compatibility evidence."""

        fk_type_norm = fk_type.upper()
        pk_type_norm = pk_type.upper()

        # Direct lookup
        compatibility = self.type_compatibility.get((fk_type_norm, pk_type_norm), 0.0)

        # Fallback logic for unknown types
        if compatibility == 0.0:
            if fk_type_norm == pk_type_norm:
                compatibility = 1.0
                explanation = f"Exact type match: {fk_type}"
            elif ("NUMBER" in fk_type_norm and "NUMBER" in pk_type_norm) or \
                 ("INT" in fk_type_norm and "INT" in pk_type_norm):
                compatibility = 0.8
                explanation = f"Compatible numeric types: {fk_type} ‚Üî {pk_type}"
            elif ("STRING" in fk_type_norm and "STRING" in pk_type_norm) or \
                 ("VARCHAR" in fk_type_norm and "VARCHAR" in pk_type_norm) or \
                 ("TEXT" in fk_type_norm and "TEXT" in pk_type_norm):
                compatibility = 0.8
                explanation = f"Compatible string types: {fk_type} ‚Üî {pk_type}"
            else:
                compatibility = 0.1
                explanation = f"Incompatible types: {fk_type} vs {pk_type}"
        else:
            explanation = f"Type compatibility: {fk_type} ‚Üî {pk_type} ({compatibility:.1f})"

        confidence_level = "high" if compatibility >= 0.8 else "medium" if compatibility >= 0.5 else "low"

        return ConfidenceEvidence(
            evidence_type=EvidenceType.TYPE_COMPATIBILITY,
            score=compatibility,
            weight=self.evidence_weights[EvidenceType.TYPE_COMPATIBILITY],
            explanation=explanation,
            confidence_level=confidence_level
        )

    def calculate_schema_patterns_evidence(
        self,
        fk_column: str,
        pk_column: str,
        fk_table: str,
        pk_table: str
    ) -> ConfidenceEvidence:
        """Calculate schema pattern evidence (naming conventions, etc.)."""

        score = 0.0
        reasons = []

        # TPC-H prefix pattern matching
        if self._follows_tpch_pattern(fk_column, pk_column, fk_table, pk_table):
            score += 0.6
            reasons.append("Follows TPC-H naming pattern")

        # Standard FK naming patterns
        if self._follows_standard_fk_pattern(fk_column, pk_column, pk_table):
            score += 0.3
            reasons.append("Follows standard FK naming")

        # Entity-table alignment
        if self._entity_table_alignment(pk_column, pk_table):
            score += 0.1
            reasons.append("PK column aligns with table entity")

        score = min(1.0, score)
        explanation = "; ".join(reasons) if reasons else "No clear schema patterns"
        confidence_level = "high" if score >= 0.7 else "medium" if score >= 0.4 else "low"

        return ConfidenceEvidence(
            evidence_type=EvidenceType.SCHEMA_PATTERNS,
            score=score,
            weight=self.evidence_weights[EvidenceType.SCHEMA_PATTERNS],
            explanation=explanation,
            confidence_level=confidence_level
        )

    def calculate_domain_knowledge_evidence(
        self,
        fk_table: str,
        pk_table: str
    ) -> ConfidenceEvidence:
        """Calculate domain knowledge evidence based on business relationships."""

        fk_entity = self._extract_table_entity(fk_table)
        pk_entity = self._extract_table_entity(pk_table)

        # Look for business relationship pattern
        pattern_key = (pk_entity, fk_entity)  # Note: PK table first in lookup
        business_info = self.business_patterns.get(pattern_key)

        if business_info:
            score = business_info["weight"]
            explanation = f"Known business relationship: {business_info['pattern']}"
            confidence_level = "high"
        else:
            # Check for reverse pattern or partial matches
            reverse_key = (fk_entity, pk_entity)
            if reverse_key in self.business_patterns:
                score = 0.3  # Lower confidence for reverse relationship
                explanation = f"Reverse business relationship detected"
                confidence_level = "medium"
            else:
                score = 0.1  # Default low score for unknown relationships
                explanation = f"No known business relationship: {fk_entity} ‚Üí {pk_entity}"
                confidence_level = "low"

        return ConfidenceEvidence(
            evidence_type=EvidenceType.DOMAIN_KNOWLEDGE,
            score=score,
            weight=self.evidence_weights[EvidenceType.DOMAIN_KNOWLEDGE],
            explanation=explanation,
            confidence_level=confidence_level
        )

    def calculate_value_containment_evidence(
        self,
        fk_values: Optional[List] = None,
        pk_values: Optional[List] = None,
        containment_ratio: float = 0.0
    ) -> ConfidenceEvidence:
        """Calculate value containment evidence (inclusion dependency)."""

        if fk_values is not None and pk_values is not None:
            # Calculate actual containment
            fk_set = set(fk_values)
            pk_set = set(pk_values)

            if len(fk_set) == 0:
                containment_ratio = 0.0
            else:
                contained = len(fk_set.intersection(pk_set))
                containment_ratio = contained / len(fk_set)

        # Score based on containment ratio
        if containment_ratio >= 0.95:
            score = 1.0
            explanation = f"Excellent value containment: {containment_ratio:.1%}"
            confidence_level = "high"
        elif containment_ratio >= 0.80:
            score = 0.8 + (containment_ratio - 0.80) * 1.33  # 0.8-1.0
            explanation = f"Good value containment: {containment_ratio:.1%}"
            confidence_level = "high"
        elif containment_ratio >= 0.60:
            score = 0.5 + (containment_ratio - 0.60) * 1.5  # 0.5-0.8
            explanation = f"Moderate value containment: {containment_ratio:.1%}"
            confidence_level = "medium"
        elif containment_ratio >= 0.30:
            score = 0.2 + (containment_ratio - 0.30) * 1.0  # 0.2-0.5
            explanation = f"Low value containment: {containment_ratio:.1%}"
            confidence_level = "low"
        else:
            score = containment_ratio * 0.67  # 0.0-0.2
            explanation = f"Very low value containment: {containment_ratio:.1%}"
            confidence_level = "low"

        return ConfidenceEvidence(
            evidence_type=EvidenceType.VALUE_CONTAINMENT,
            score=score,
            weight=self.evidence_weights[EvidenceType.VALUE_CONTAINMENT],
            explanation=explanation,
            confidence_level=confidence_level
        )

    def calculate_comprehensive_confidence(
        self,
        fk_table: str,
        fk_column: str,
        fk_type: str,
        pk_table: str,
        pk_column: str,
        pk_type: str,
        fk_values: Optional[List] = None,
        pk_values: Optional[List] = None,
        containment_ratio: float = 0.0
    ) -> RelationshipCandidate:
        """Calculate comprehensive confidence using all evidence types."""

        evidence_scores = {}

        # Calculate all evidence types
        evidence_scores[EvidenceType.NAME_SIMILARITY] = self.calculate_name_similarity_evidence(
            fk_column, pk_column, fk_table, pk_table
        )

        evidence_scores[EvidenceType.TYPE_COMPATIBILITY] = self.calculate_type_compatibility_evidence(
            fk_type, pk_type
        )

        evidence_scores[EvidenceType.SCHEMA_PATTERNS] = self.calculate_schema_patterns_evidence(
            fk_column, pk_column, fk_table, pk_table
        )

        evidence_scores[EvidenceType.DOMAIN_KNOWLEDGE] = self.calculate_domain_knowledge_evidence(
            fk_table, pk_table
        )

        evidence_scores[EvidenceType.VALUE_CONTAINMENT] = self.calculate_value_containment_evidence(
            fk_values, pk_values, containment_ratio
        )

        # Placeholder for statistical and cardinality analysis
        evidence_scores[EvidenceType.STATISTICAL_ANALYSIS] = ConfidenceEvidence(
            evidence_type=EvidenceType.STATISTICAL_ANALYSIS,
            score=0.5,  # Default neutral score
            weight=self.evidence_weights[EvidenceType.STATISTICAL_ANALYSIS],
            explanation="Statistical analysis not implemented",
            confidence_level="medium"
        )

        evidence_scores[EvidenceType.CARDINALITY_ANALYSIS] = ConfidenceEvidence(
            evidence_type=EvidenceType.CARDINALITY_ANALYSIS,
            score=0.5,  # Default neutral score
            weight=self.evidence_weights[EvidenceType.CARDINALITY_ANALYSIS],
            explanation="Cardinality analysis not implemented",
            confidence_level="medium"
        )

        # Calculate weighted final confidence
        weighted_sum = 0.0
        total_weight = 0.0

        for evidence in evidence_scores.values():
            weighted_sum += evidence.score * evidence.weight
            total_weight += evidence.weight

        final_confidence = weighted_sum / total_weight if total_weight > 0 else 0.0

        # Determine quality tier and recommendation
        if final_confidence >= 0.8:
            quality_tier = "excellent"
            recommendation = "Strong relationship candidate - high confidence"
        elif final_confidence >= 0.65:
            quality_tier = "good"
            recommendation = "Good relationship candidate - recommend inclusion"
        elif final_confidence >= 0.45:
            quality_tier = "fair"
            recommendation = "Moderate confidence - requires additional validation"
        else:
            quality_tier = "poor"
            recommendation = "Low confidence - likely false positive"

        return RelationshipCandidate(
            fk_table=fk_table,
            fk_column=fk_column,
            pk_table=pk_table,
            pk_column=pk_column,
            evidence_scores=evidence_scores,
            final_confidence=final_confidence,
            quality_tier=quality_tier,
            recommendation=recommendation
        )

    # Helper methods
    def _extract_core_entity(self, column_name: str) -> str:
        """Extract core entity from column name."""
        if not column_name:
            return ""

        name_upper = column_name.upper()

        # Remove table prefix (e.g., C_CUSTKEY -> CUSTKEY)
        if "_" in name_upper:
            parts = name_upper.split("_", 1)
            if len(parts) == 2 and len(parts[0]) <= 2:
                core_part = parts[1]
            else:
                core_part = name_upper
        else:
            core_part = name_upper

        # Remove common suffixes
        for suffix in ["KEY", "ID", "NUM", "NO"]:
            if core_part.endswith(suffix):
                return core_part[:-len(suffix)]

        return core_part

    def _are_entity_variants(self, entity1: str, entity2: str) -> bool:
        """Check if two entities are variants of the same concept."""
        if not entity1 or not entity2:
            return False

        # Direct entity mapping lookup
        for entity, variants in self.tpch_entities.items():
            if entity1 in variants and entity2 in variants:
                return True
            if entity1 == entity and entity2 in variants:
                return True
            if entity2 == entity and entity1 in variants:
                return True

        return False

    def _calculate_levenshtein_similarity(self, s1: str, s2: str) -> float:
        """Calculate Levenshtein-based similarity."""
        if not s1 or not s2:
            return 0.0

        # Normalize for comparison
        norm1 = s1.upper().replace("_", "").replace("-", "")
        norm2 = s2.upper().replace("_", "").replace("-", "")

        if norm1 == norm2:
            return 1.0

        distance = self._levenshtein_distance(norm1, norm2)
        max_len = max(len(norm1), len(norm2))

        if max_len == 0:
            return 0.0

        return max(0.0, 1.0 - (distance / max_len))

    def _levenshtein_distance(self, s1: str, s2: str) -> int:
        """Calculate Levenshtein distance."""
        if len(s1) < len(s2):
            return self._levenshtein_distance(s2, s1)

        if len(s2) == 0:
            return len(s1)

        previous_row = list(range(len(s2) + 1))
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row

        return previous_row[-1]

    def _follows_tpch_pattern(self, fk_column: str, pk_column: str, fk_table: str, pk_table: str) -> bool:
        """Check if columns follow TPC-H naming patterns."""
        fk_upper = fk_column.upper()
        pk_upper = pk_column.upper()

        # TPC-H pattern: {table_prefix}_{entity}KEY
        if "_" in fk_upper and "_" in pk_upper:
            fk_parts = fk_upper.split("_")
            pk_parts = pk_upper.split("_")

            if len(fk_parts) >= 2 and len(pk_parts) >= 2:
                fk_entity = "_".join(fk_parts[1:])
                pk_entity = "_".join(pk_parts[1:])

                # Check if they refer to the same entity concept
                if fk_entity == pk_entity:
                    return True

                # Check entity variants
                fk_core = self._extract_core_entity(fk_entity)
                pk_core = self._extract_core_entity(pk_entity)

                if self._are_entity_variants(fk_core, pk_core):
                    return True

        return False

    def _follows_standard_fk_pattern(self, fk_column: str, pk_column: str, pk_table: str) -> bool:
        """Check if columns follow standard FK naming patterns."""
        fk_upper = fk_column.upper()
        pk_upper = pk_column.upper()
        pk_table_upper = pk_table.upper()

        # Pattern 1: FK = {table}_{pk_column}
        expected_fk1 = f"{pk_table_upper}_{pk_upper}"
        if fk_upper == expected_fk1:
            return True

        # Pattern 2: FK contains PK column name
        if pk_upper in fk_upper and len(pk_upper) >= 3:
            return True

        # Pattern 3: Both end with same suffix (e.g., KEY, ID)
        for suffix in ["KEY", "ID"]:
            if fk_upper.endswith(suffix) and pk_upper.endswith(suffix):
                fk_base = fk_upper[:-len(suffix)]
                pk_base = pk_upper[:-len(suffix)]

                # Check if bases are related
                if pk_base in fk_base or self._are_entity_variants(fk_base, pk_base):
                    return True

        return False

    def _entity_table_alignment(self, pk_column: str, pk_table: str) -> bool:
        """Check if PK column aligns with its table entity."""
        pk_entity = self._extract_core_entity(pk_column)
        table_entity = self._extract_table_entity(pk_table)

        return self._are_entity_variants(pk_entity, table_entity)

    def _extract_table_entity(self, table_name: str) -> str:
        """Extract entity concept from table name."""
        table_upper = table_name.upper()

        # Handle plurals
        if table_upper.endswith("S") and len(table_upper) > 3:
            singular = table_upper[:-1]
            # Check if singular form is a known entity
            if singular in self.tpch_entities or singular in self.entity_abbreviations:
                return singular

        return table_upper


def test_advanced_scoring():
    """Test the advanced confidence scoring system."""

    scorer = AdvancedConfidenceScorer()

    print("=" * 80)
    print("ADVANCED MULTI-FACTOR CONFIDENCE SCORING TEST")
    print("=" * 80)

    # Test cases with expected relationships
    test_cases = [
        {
            "fk_table": "ORDERS", "fk_column": "O_CUSTKEY", "fk_type": "NUMBER",
            "pk_table": "CUSTOMER", "pk_column": "C_CUSTKEY", "pk_type": "NUMBER",
            "containment_ratio": 0.95, "expected": "excellent"
        },
        {
            "fk_table": "CUSTOMER", "fk_column": "C_NATIONKEY", "fk_type": "NUMBER",
            "pk_table": "NATION", "pk_column": "N_NATIONKEY", "pk_type": "NUMBER",
            "containment_ratio": 1.0, "expected": "excellent"
        },
        {
            "fk_table": "LINEITEM", "fk_column": "L_ORDERKEY", "fk_type": "NUMBER",
            "pk_table": "ORDERS", "pk_column": "O_ORDERKEY", "pk_type": "NUMBER",
            "containment_ratio": 0.98, "expected": "excellent"
        },
        # Negative case
        {
            "fk_table": "CUSTOMER", "fk_column": "C_NATIONKEY", "fk_type": "NUMBER",
            "pk_table": "REGION", "pk_column": "R_REGIONKEY", "pk_type": "NUMBER",
            "containment_ratio": 0.2, "expected": "poor"
        }
    ]

    print("\nüß™ TESTING COMPREHENSIVE CONFIDENCE CALCULATION:")

    for i, case in enumerate(test_cases, 1):
        result = scorer.calculate_comprehensive_confidence(
            fk_table=case["fk_table"],
            fk_column=case["fk_column"],
            fk_type=case["fk_type"],
            pk_table=case["pk_table"],
            pk_column=case["pk_column"],
            pk_type=case["pk_type"],
            containment_ratio=case["containment_ratio"]
        )

        status = "‚úÖ PASS" if result.quality_tier == case["expected"] else "‚ùå FAIL"

        print(f"\n{status} Test {i}: {case['fk_table']}.{case['fk_column']} ‚Üí {case['pk_table']}.{case['pk_column']}")
        print(f"   Final Confidence: {result.final_confidence:.3f}")
        print(f"   Quality Tier: {result.quality_tier} (expected: {case['expected']})")
        print(f"   Recommendation: {result.recommendation}")

        # Show top evidence factors
        sorted_evidence = sorted(
            result.evidence_scores.values(),
            key=lambda e: e.score * e.weight,
            reverse=True
        )

        print(f"   Top Evidence:")
        for evidence in sorted_evidence[:3]:
            weighted_score = evidence.score * evidence.weight
            print(f"     ‚Ä¢ {evidence.evidence_type.value}: {evidence.score:.3f} (w:{weighted_score:.3f}) - {evidence.explanation}")

    print("\n" + "=" * 80)
    print("üéØ ADVANCED SCORING SYSTEM READY")
    print("=" * 80)
    print("Multi-factor confidence model successfully implemented with:")
    print("‚Ä¢ 7 evidence types with weighted scoring")
    print("‚Ä¢ TPC-H domain knowledge integration")
    print("‚Ä¢ Comprehensive pattern matching")
    print("‚Ä¢ Quality tier classification")
    print("‚Ä¢ Detailed explanations and recommendations")


if __name__ == "__main__":
    test_advanced_scoring()